{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.15","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"TPU","colab":{"gpuType":"V28","provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9758570,"sourceType":"datasetVersion","datasetId":5975432}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pickle # lưu trữ và tải dữ liệu dạng nhị phân","metadata":{"executionInfo":{"elapsed":673,"status":"ok","timestamp":1730251016458,"user":{"displayName":"Phước Đô","userId":"08454652479642886827"},"user_tz":-420},"id":"american-headquarters","execution":{"iopub.status.busy":"2024-11-05T15:42:52.240909Z","iopub.execute_input":"2024-11-05T15:42:52.241166Z","iopub.status.idle":"2024-11-05T15:42:52.77273Z","shell.execute_reply.started":"2024-11-05T15:42:52.24114Z","shell.execute_reply":"2024-11-05T15:42:52.772043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def unpickle(file):  # Mở đọc file dạng nhị phân --> trả về dữ liệu đã giải mã\n    with open(file, 'rb') as fo:\n        d = pickle.load(fo, encoding='bytes')\n    return d\n\ndef load_cifar(filenames):\n    training_images = []\n    training_labels = []\n\n    for file_name in filenames:\n        unpickled_images = unpickle(file_name)\n        images, labels = unpickled_images[b'data'], unpickled_images[b'labels']  # Lấy ảnh và nhãn,\n        #'b' --> do khi đọc dữ liệu dạng nhị phân, dữ liệu được lưu dạng byte, vì vậy các khóa có dạng byte string\n                                                     # Dữ liệu gốc (số lượng, 32x32x3) với số cột 1024: R, 1024:G, 1024:B\n        images = np.reshape(images,(-1, 3, 32, 32))  # (number_of_images, channels (RGB), height, width)\n        images = np.transpose(images, (0, 2, 3, 1))  # (number_of_images, height, width, channels (RGB)) --> phù hợp với hầu hết các thư viện xử lí ảnh và học sâu\n        training_images.append(images)\n        training_labels += labels\n\n    return np.vstack(training_images), training_labels  # xếp chồng các theo trục đầu tiên --> trả về mảng chứa tất cả các ảnh\n\nprint(\"Loading the training set\")\ntraining_files = [f'/kaggle/input/chap-6/data_batch_{i}' for i in range(1, 6)]\ntraining_images, int_training_labels = load_cifar(training_files)\n\nprint(\"Loading the testing set\")\ntraining_files = ['/kaggle/input/chap-6/test_batch']\ntesting_images, int_testing_labels = load_cifar(training_files)\n\nprint(\"Loading the labels\")\nlabel_names = unpickle('/kaggle/input/chap-6/batches.meta')[b'label_names']\ntraining_labels = [str(label_names[i]) for i in int_training_labels]\ntesting_labels = [str(label_names[i]) for i in int_testing_labels]\n","metadata":{"executionInfo":{"elapsed":14943,"status":"ok","timestamp":1730251031398,"user":{"displayName":"Phước Đô","userId":"08454652479642886827"},"user_tz":-420},"id":"varied-participant","outputId":"c11f01e0-004e-4e9f-cf85-0e0a4449feb4","execution":{"iopub.status.busy":"2024-11-05T15:42:52.774135Z","iopub.execute_input":"2024-11-05T15:42:52.774498Z","iopub.status.idle":"2024-11-05T15:42:54.426099Z","shell.execute_reply.started":"2024-11-05T15:42:52.774466Z","shell.execute_reply":"2024-11-05T15:42:54.425337Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"', '.join([l.decode() for l in label_names]) # kết hợp các nhãn thành một chuỗi duy nhất, mỗi nhãn cách nhau bởi dấu phẩy và khoảng trắng.","metadata":{"executionInfo":{"elapsed":451,"status":"ok","timestamp":1730251071108,"user":{"displayName":"Phước Đô","userId":"08454652479642886827"},"user_tz":-420},"id":"legislative-method","outputId":"6fb6b9fe-85d9-4ab0-cb18-348f50347559","execution":{"iopub.status.busy":"2024-11-05T15:42:54.426965Z","iopub.execute_input":"2024-11-05T15:42:54.427215Z","iopub.status.idle":"2024-11-05T15:42:54.434035Z","shell.execute_reply.started":"2024-11-05T15:42:54.427191Z","shell.execute_reply":"2024-11-05T15:42:54.433389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt # hiển thị một hình ảnh từ tập dữ liệu huấn luyện \nprint(training_labels[0])\nplt.imshow(training_images[0])\nplt.title(training_labels[0])","metadata":{"executionInfo":{"elapsed":900,"status":"ok","timestamp":1730251096472,"user":{"displayName":"Phước Đô","userId":"08454652479642886827"},"user_tz":-420},"id":"exotic-frank","outputId":"446c8326-d9ef-4555-bca3-0e4892774025","execution":{"iopub.status.busy":"2024-11-05T15:42:54.435657Z","iopub.execute_input":"2024-11-05T15:42:54.436056Z","iopub.status.idle":"2024-11-05T15:42:55.624062Z","shell.execute_reply.started":"2024-11-05T15:42:54.436017Z","shell.execute_reply":"2024-11-05T15:42:55.623076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(testing_labels[0]) # hiển thị một hình ảnh từ tập dữ liệu kiểm tra\nplt.imshow(testing_images[0])","metadata":{"executionInfo":{"elapsed":427,"status":"ok","timestamp":1730251118758,"user":{"displayName":"Phước Đô","userId":"08454652479642886827"},"user_tz":-420},"id":"premier-rocket","outputId":"d566aa9f-7ac1-443f-bf81-a18dc9fa1fc2","execution":{"iopub.status.busy":"2024-11-05T15:42:55.625224Z","iopub.execute_input":"2024-11-05T15:42:55.625573Z","iopub.status.idle":"2024-11-05T15:42:55.760898Z","shell.execute_reply.started":"2024-11-05T15:42:55.625543Z","shell.execute_reply":"2024-11-05T15:42:55.760244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_images.shape","metadata":{"executionInfo":{"elapsed":416,"status":"ok","timestamp":1730251127609,"user":{"displayName":"Phước Đô","userId":"08454652479642886827"},"user_tz":-420},"id":"accessory-january","outputId":"1f0e8a3e-ef75-48ff-c9ef-15a944f8628f","execution":{"iopub.status.busy":"2024-11-05T15:42:55.762093Z","iopub.execute_input":"2024-11-05T15:42:55.762365Z","iopub.status.idle":"2024-11-05T15:42:55.767487Z","shell.execute_reply.started":"2024-11-05T15:42:55.762337Z","shell.execute_reply":"2024-11-05T15:42:55.766836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_images[0][0, 0]  # Truy cập 1 pixel cụ thể của 1 ảnh","metadata":{"executionInfo":{"elapsed":468,"status":"ok","timestamp":1730251240921,"user":{"displayName":"Phước Đô","userId":"08454652479642886827"},"user_tz":-420},"id":"retained-glasgow","outputId":"bf1a5818-1afa-481b-c404-b87e459c5681","execution":{"iopub.status.busy":"2024-11-05T15:42:55.768482Z","iopub.execute_input":"2024-11-05T15:42:55.768722Z","iopub.status.idle":"2024-11-05T15:42:55.789222Z","shell.execute_reply.started":"2024-11-05T15:42:55.768697Z","shell.execute_reply":"2024-11-05T15:42:55.78835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Sử dụng trực tiếp pixel làm đặc trưng","metadata":{"id":"8vdvL9eCFzpe"}},{"cell_type":"code","source":"avg_training_images = training_images.mean(axis=3).reshape(50000,-1) # chuyển đổi ảnh màu trong tập huấn luyện và kiểm tra thành ảnh xám\navg_testing_images = testing_images.mean(axis=3).reshape(10000,-1)\n# (50000, 32, 32, 3) -->(50000, 32, 32) --> (50000, 32*32) = (50000, 1024) # sau đó \"trải phẳng\" từng ảnh xám thành một mảng một chiều 1024 phần tử\nprint(avg_training_images.shape)","metadata":{"executionInfo":{"elapsed":839,"status":"ok","timestamp":1730252609777,"user":{"displayName":"Phước Đô","userId":"08454652479642886827"},"user_tz":-420},"id":"intended-junior","outputId":"3453dee9-39c0-46fd-93fa-3517e79ae69e","execution":{"iopub.status.busy":"2024-11-05T15:42:55.790282Z","iopub.execute_input":"2024-11-05T15:42:55.790533Z","iopub.status.idle":"2024-11-05T15:42:56.150148Z","shell.execute_reply.started":"2024-11-05T15:42:55.790508Z","shell.execute_reply":"2024-11-05T15:42:56.149188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(training_images.mean(axis=3)[0], cmap='gray') # hiển thị ảnh đầu tiên trong tập dữ dưới dạng ảnh xám ","metadata":{"executionInfo":{"elapsed":985,"status":"ok","timestamp":1730252613464,"user":{"displayName":"Phước Đô","userId":"08454652479642886827"},"user_tz":-420},"id":"magnetic-tuning","outputId":"91981a95-d642-4559-cdf9-a71829683a78","execution":{"iopub.status.busy":"2024-11-05T15:42:56.151297Z","iopub.execute_input":"2024-11-05T15:42:56.15158Z","iopub.status.idle":"2024-11-05T15:42:56.582971Z","shell.execute_reply.started":"2024-11-05T15:42:56.151553Z","shell.execute_reply":"2024-11-05T15:42:56.58198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%run /kaggle/input/chap-6/Base.ipynb","metadata":{"executionInfo":{"elapsed":449,"status":"ok","timestamp":1730252616219,"user":{"displayName":"Phước Đô","userId":"08454652479642886827"},"user_tz":-420},"id":"structured-fruit","execution":{"iopub.status.busy":"2024-11-05T15:42:56.586355Z","iopub.execute_input":"2024-11-05T15:42:56.586643Z","iopub.status.idle":"2024-11-05T15:42:59.888922Z","shell.execute_reply.started":"2024-11-05T15:42:56.586615Z","shell.execute_reply":"2024-11-05T15:42:59.888077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\n\nclf = LogisticRegression(max_iter=100, solver='saga')  # solver: xác định bộ giải được sử dụng để tối ưu hóa trọng số của mô hình.\n\nml_pipeline = Pipeline([\n    ('classifier', # tên bước\n     clf  # đối tượng mô hình\n     )\n])\n\nparams = {\n    'classifier__C': [1e-1, 1e0, 1e1] # chỉ định giá trị tham số C --> Tham số C điều chỉnh mức độ regularization trong mô hình\n}\n\nprint(\"Average Pixel Value + LogReg\\n==========================\")\nadvanced_grid_search(   # D\n    avg_training_images, training_labels, avg_testing_images, testing_labels,\n    ml_pipeline, params\n)\n","metadata":{"executionInfo":{"elapsed":1865516,"status":"ok","timestamp":1730254838999,"user":{"displayName":"Phước Đô","userId":"08454652479642886827"},"user_tz":-420},"id":"widespread-rainbow","outputId":"cdafa714-b93f-4c2f-cf7e-a8bc714bbac6","scrolled":true,"execution":{"iopub.status.busy":"2024-11-05T15:42:59.889847Z","iopub.execute_input":"2024-11-05T15:42:59.890215Z","iopub.status.idle":"2024-11-05T16:05:22.834279Z","shell.execute_reply.started":"2024-11-05T15:42:59.890189Z","shell.execute_reply":"2024-11-05T16:05:22.833568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Trích xuất đặc trưng:HOG(Histogram of oriented gradients)\n","metadata":{"id":"B7RJVaymJgyo"}},{"cell_type":"code","source":"# tính toán và hiển thị tính năng Histogram of Oriented Gradients (HOG) của các hình ảnh trong training_images\nfrom skimage.feature import hog \n\nfor image in training_images[:3]:\n\n    hog_features, hog_image = hog(\n        image,\n        orientations=8,\n        pixels_per_cell=(4, 4),\n        cells_per_block=(2, 2),\n        visualize=True,\n        channel_axis=-1,\n        transform_sqrt=True,\n        block_norm='L2-Hys'\n        )\n\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4), sharex=True, sharey=True)\n\n    ax1.axis('off')\n    ax1.imshow(image, cmap=plt.cm.gray)\n    ax1.set_title('Input image')\n\n    ax2.axis('off')\n    ax2.imshow(hog_image, cmap=plt.cm.gray)\n    ax2.set_title('Histogram of Oriented Gradients')\n\nprint(hog_features.shape)\nplt.show()\n","metadata":{"executionInfo":{"elapsed":1267,"status":"ok","timestamp":1730254841734,"user":{"displayName":"Phước Đô","userId":"08454652479642886827"},"user_tz":-420},"id":"smart-harvard","outputId":"1f960172-4e87-4506-d12d-ab9bb35b0d10","scrolled":true,"execution":{"iopub.status.busy":"2024-11-05T16:05:22.835314Z","iopub.execute_input":"2024-11-05T16:05:22.835576Z","iopub.status.idle":"2024-11-05T16:05:23.28806Z","shell.execute_reply.started":"2024-11-05T16:05:22.835551Z","shell.execute_reply":"2024-11-05T16:05:23.287353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n#tqdm sẽ cung cấp cho chúng ta một thanh tiến trình để chúng ta có thể thấy mất bao lâu để tính toán HOGs.\n\ndef calculate_hogs(images):\n    hog_descriptors = []\n    for image in tqdm(np.sqrt(images)):\n        hog_descriptors.append(hog(\n            image, orientations=8, pixels_per_cell=(4, 4), cells_per_block=(2, 2),\n            channel_axis=-1, transform_sqrt=True, block_norm='L2-Hys', visualize=False\n        ))\n\n    return np.squeeze(hog_descriptors)\n\nhog_training = calculate_hogs(training_images)\nhog_testing = calculate_hogs(testing_images)","metadata":{"executionInfo":{"elapsed":126523,"status":"ok","timestamp":1730254968253,"user":{"displayName":"Phước Đô","userId":"08454652479642886827"},"user_tz":-420},"id":"nervous-dayton","outputId":"b4af839d-fcc8-42da-fe95-185f36da4600","execution":{"iopub.status.busy":"2024-11-05T16:05:23.289138Z","iopub.execute_input":"2024-11-05T16:05:23.28956Z","iopub.status.idle":"2024-11-05T16:06:56.917456Z","shell.execute_reply.started":"2024-11-05T16:05:23.289528Z","shell.execute_reply":"2024-11-05T16:06:56.916603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hog_training.shape","metadata":{"executionInfo":{"elapsed":465,"status":"ok","timestamp":1730254968711,"user":{"displayName":"Phước Đô","userId":"08454652479642886827"},"user_tz":-420},"id":"combined-apartment","outputId":"b28b5136-07a6-4ae5-8c9f-316df0242548","execution":{"iopub.status.busy":"2024-11-05T16:06:56.918686Z","iopub.execute_input":"2024-11-05T16:06:56.918956Z","iopub.status.idle":"2024-11-05T16:06:56.924554Z","shell.execute_reply.started":"2024-11-05T16:06:56.918928Z","shell.execute_reply":"2024-11-05T16:06:56.92376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hog_testing.shape","metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1730254968712,"user":{"displayName":"Phước Đô","userId":"08454652479642886827"},"user_tz":-420},"id":"absolute-excellence","outputId":"3d13940c-2c25-430b-c0b4-ba44ae64f229","execution":{"iopub.status.busy":"2024-11-05T16:06:56.925617Z","iopub.execute_input":"2024-11-05T16:06:56.92594Z","iopub.status.idle":"2024-11-05T16:06:56.944999Z","shell.execute_reply.started":"2024-11-05T16:06:56.925913Z","shell.execute_reply":"2024-11-05T16:06:56.944348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"HOG + LogReg\\n=====================\")\nadvanced_grid_search(\n    hog_training, training_labels, hog_testing, testing_labels,\n    ml_pipeline, params\n)","metadata":{"id":"second-senior","outputId":"4a728c6b-f291-40d7-9e42-b497968f132c","execution":{"iopub.status.busy":"2024-11-05T16:06:56.945876Z","iopub.execute_input":"2024-11-05T16:06:56.946127Z","iopub.status.idle":"2024-11-05T16:42:43.29046Z","shell.execute_reply.started":"2024-11-05T16:06:56.946103Z","shell.execute_reply":"2024-11-05T16:42:43.289617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tối ưu hóa giảm chiều bằng PCA","metadata":{"id":"qwq8beSGNvbs"}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\n\nnum_hog_features = hog_training.shape[1]  # B\n\np = PCA(n_components=num_hog_features)  # C\np.fit(hog_training)  # C\n\nplt.plot(p.explained_variance_ratio_.cumsum())  # D\nplt.title('Explained Variance vs # of PCA Components')\nplt.xlabel('Number of Components')\nplt.ylabel('% of Explained Variance')\n\n# A Nhập mô-đun PCA từ thư viện scikit-learn để thực hiện giảm chiều\n# B Số lượng đặc trưng từ phép biến đổi HOG ban đầu\n# C Khớp mô hình PCA với ma trận HOG.\n# D Trực quan hóa xác định số lượng thành phần chính cần thiết cho việc giảm chiều.","metadata":{"id":"cEE2Gf51UHwV","execution":{"iopub.status.busy":"2024-11-05T16:42:43.291548Z","iopub.execute_input":"2024-11-05T16:42:43.292081Z","iopub.status.idle":"2024-11-05T16:42:47.11998Z","shell.execute_reply.started":"2024-11-05T16:42:43.292051Z","shell.execute_reply":"2024-11-05T16:42:47.119185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  đánh giá xem việc giữ lại bao nhiêu thành phần chính là hợp lý để giải thích được phần lớn biến động của dữ liệu.\nexplained_variance = p.explained_variance_ratio_.cumsum()\n\nfor i in [10, 100, 200, 400]:\n    print(f'The explained variance using {i} components is {explained_variance[i - 1]}')","metadata":{"id":"prostate-raleigh","execution":{"iopub.status.busy":"2024-11-05T16:42:47.121112Z","iopub.execute_input":"2024-11-05T16:42:47.121473Z","iopub.status.idle":"2024-11-05T16:42:47.126606Z","shell.execute_reply.started":"2024-11-05T16:42:47.121442Z","shell.execute_reply":"2024-11-05T16:42:47.125815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p = PCA(n_components=600)  # A\n\nhog_training_pca = p.fit_transform(hog_training)  # B\nhog_testing_pca = p.transform(hog_testing)  # B\n\nprint(\"HOG + PCA + LogReg\\n=====================\")\nadvanced_grid_search(  # C\n    hog_training_pca, training_labels, hog_testing_pca, testing_labels,\n    ml_pipeline, params\n)\n\n# A Chọn để trích xuất 600 đặc trưng mới.\n# B Chuyển đổi các đặc trưng HOG gốc thành không gian giảm chiều\n# C Lấy độ chính xác cho các đặc trưng HOG đã giảm chiều.","metadata":{"id":"yellow-duncan","execution":{"iopub.status.busy":"2024-11-05T16:42:47.127742Z","iopub.execute_input":"2024-11-05T16:42:47.128017Z","iopub.status.idle":"2024-11-05T16:53:15.501711Z","shell.execute_reply.started":"2024-11-05T16:42:47.127988Z","shell.execute_reply":"2024-11-05T16:53:15.50087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature learning with VGG-11","metadata":{"id":"4t1FGJAYQ_zM"}},{"cell_type":"code","source":"import torchvision.models as models\nimport torch.nn as nn\n\nvgg_model = models.vgg11(pretrained='imagenet')  # A\n\nnormalized_training_images = ((training_images/255) - [0.485, 0.456, 0.406]) / [0.229, 0.224, 0.225]  # B\nnormalized_testing_images = ((testing_images/255) - [0.485, 0.456, 0.406]) / [0.229, 0.224, 0.225]  # B\n\n# A Khởi tạo một mô hình VGG-11 đã được huấn luyện trước trên bộ dữ liệu ImageNet\n# B Chuẩn hóa các hình ảnh thô sử dụng các giá trị từ nghiên cứu gốc","metadata":{"id":"popular-parent","execution":{"iopub.status.busy":"2024-11-05T16:53:15.502832Z","iopub.execute_input":"2024-11-05T16:53:15.503144Z","iopub.status.idle":"2024-11-05T16:53:45.301571Z","shell.execute_reply.started":"2024-11-05T16:53:15.503113Z","shell.execute_reply":"2024-11-05T16:53:45.300734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg_model","metadata":{"id":"structured-addiction","execution":{"iopub.status.busy":"2024-11-05T16:53:45.302652Z","iopub.execute_input":"2024-11-05T16:53:45.303064Z","iopub.status.idle":"2024-11-05T16:53:45.30831Z","shell.execute_reply.started":"2024-11-05T16:53:45.303035Z","shell.execute_reply":"2024-11-05T16:53:45.307658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import TensorDataset, DataLoader\n\ntraining_images_tensor = torch.Tensor(normalized_training_images.transpose(0, 3, 1, 2))  # A\ntraining_labels_tensor = torch.Tensor(int_training_labels).type(torch.LongTensor)  # A\n\ntraining_dataset = TensorDataset(training_images_tensor, training_labels_tensor)  # A\ntraining_dataloader = DataLoader(training_dataset, shuffle=True, batch_size=2048)  # A\n\n\ntesting_images_tensor = torch.Tensor(normalized_testing_images.transpose(0, 3, 1, 2))  # B\ntesting_labels_tensor = torch.Tensor(int_testing_labels).type(torch.LongTensor)  # B\n\ntesting_dataset = TensorDataset(testing_images_tensor, testing_labels_tensor)  # B\ntesting_dataloader = DataLoader(testing_dataset, shuffle=True, batch_size=2048)  # B\n\n# A Chuyển đổi dữ liệu huấn luyện chuẩn hóa thành PyTorch DataLoader\n# B Chuyển đổi dữ liệu kiểm tra chuẩn hóa thành PyTorch DataLoader","metadata":{"id":"filled-speed","execution":{"iopub.status.busy":"2024-11-05T16:53:45.309268Z","iopub.execute_input":"2024-11-05T16:53:45.309495Z","iopub.status.idle":"2024-11-05T16:53:48.169491Z","shell.execute_reply.started":"2024-11-05T16:53:45.309472Z","shell.execute_reply":"2024-11-05T16:53:48.168534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm # thư viện giúp hiển thị thanh tiến trình\n\ndef get_vgg_features(feature_extractor): # mô hình này sẽ được sử dụng để trích xuất các đặc trưng từ hình ảnh.\n    print(\"Extracting features for training set\") # việc trích xuất đặc trưng cho tập huấn luyện đang được thực hiện.\n    extracted_training_images = [] # tạo danh sách để chứa các đặc trưng và nhãn của dữ liệu huấn luyện.\n    shuffled_training_labels = []\n    for batch_idx, (data_, target_) in tqdm(enumerate(training_dataloader)): # A\n        extracted_training_images.append(feature_extractor(data_).detach().numpy().squeeze((2, 3))) # A\n        shuffled_training_labels += target_ # A\n\n    print(\"Extracting features for testing set\") # việc trích xuất đặc trưng cho tập kiểm tra đang được thực hiện.\n    extracted_testing_images = [] # tạo danh sách để chứa các đặc trưng và nhãn của dữ liệu kiểm tra.\n    shuffled_testing_labels = []\n    for batch_idx, (data_, target_) in tqdm(enumerate(testing_dataloader)): # B\n        extracted_testing_images.append(feature_extractor(data_).detach().numpy().squeeze((2, 3))) # B\n        shuffled_testing_labels += target_ # B\n\n    return np.vstack(extracted_training_images), shuffled_training_labels, np.vstack(extracted_testing_images), shuffled_testing_labels\n#A Dữ liệu và nhãn của tập huấn luyện được lấy từ training_dataloader và các đặc trưng được trích xuất bằng cách sử dụng feature_extractor.\n#B Dữ liệu và nhãn của tập kiểm tra được lấy từ testing_dataloader và các đặc trưng được trích xuất bằng cách sử dụng feature_extractor.","metadata":{"id":"accomplished-contract","execution":{"iopub.status.busy":"2024-11-05T16:53:48.170762Z","iopub.execute_input":"2024-11-05T16:53:48.171142Z","iopub.status.idle":"2024-11-05T16:53:48.270671Z","shell.execute_reply.started":"2024-11-05T16:53:48.171108Z","shell.execute_reply":"2024-11-05T16:53:48.269781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformed_training_images, shuffled_training_labels, transformed_testing_images, shuffled_testing_labels = get_vgg_features(vgg_model.features)  # A\n\nprint(\"VGG11(Imagenet) + LogReg\\n=====================\")\nadvanced_grid_search(\n    transformed_training_images, shuffled_training_labels, # B\n    transformed_testing_images, shuffled_testing_labels,   # B\n    ml_pipeline, params\n)\n\n# A trích xuất các đặc trưng từ mô hình VGG11 đã được huấn luyện trước trên Imagenet.\n# B Việc gọi lại nhãn từ shuffled_training_labels và shuffled_testing_labels là cần thiết vì trong quá trình lấy dữ liệu từ DataLoader, các nhãn có thể đã bị xáo trộn.","metadata":{"id":"accessory-converter","execution":{"iopub.status.busy":"2024-11-05T16:53:48.271672Z","iopub.execute_input":"2024-11-05T16:53:48.27193Z","iopub.status.idle":"2024-11-05T17:08:38.996474Z","shell.execute_reply.started":"2024-11-05T16:53:48.271905Z","shell.execute_reply":"2024-11-05T17:08:38.995607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')  # A\n\nfine_tuned_vgg_model = models.vgg11(pretrained='imagenet')  # B\n\nfine_tuned_vgg_model.classifier[-1].out_features = 10  # C\n\nfor layer in fine_tuned_vgg_model.classifier:  # D\n    if hasattr(layer, 'weight'):  # D\n        torch.nn.init.xavier_uniform_(layer.weight)  # D\n    if hasattr(layer, 'bias'):  # D\n        nn.init.constant_(layer.bias.data, 0)  # D\n\n# A Kiểm tra và thiết lập thiết bị tính toán (GPU hoặc CPU).\n# B Tải mô hình VGG-11 mới\n# C Thay đổi số lớp đầu ra của mô hình thành 10 lớp thay cho 1,000 (cho tác vụ phân loại với 10 lớp).\n# D Duyệt qua các lớp trong phần classifier và khởi tạo lại trọng số và bias của chúng, giúp tinh chỉnh mô hình bắt đầu từ trạng thái ngẫu nhiên thay vì giá trị mặc định.","metadata":{"id":"amber-halloween","execution":{"iopub.status.busy":"2024-11-05T17:08:38.997671Z","iopub.execute_input":"2024-11-05T17:08:38.997949Z","iopub.status.idle":"2024-11-05T17:08:41.291943Z","shell.execute_reply.started":"2024-11-05T17:08:38.997923Z","shell.execute_reply":"2024-11-05T17:08:41.290839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim  # A\n\ncriterion = nn.CrossEntropyLoss()  # A\noptimizer = optim.SGD(fine_tuned_vgg_model.parameters(), lr=0.01, momentum=0.9)  # A\n\nn_epochs = 15  # A\nprint_every = 10  # A\nvalid_loss_min = np.Inf  # A\ntotal_step = len(training_dataloader)  # A\n\ntrain_loss, val_loss, train_acc, val_acc = [], [], [], []  # B\n\n\n# A Đặt các tham số huấn luyện (điều chỉnh tham số chạy ngầm off-screeen)\n# B Khởi tạo danh sách để theo dõi mất mát và độ chính xác","metadata":{"id":"printable-circus","execution":{"iopub.status.busy":"2024-11-05T17:08:41.293243Z","iopub.execute_input":"2024-11-05T17:08:41.293508Z","iopub.status.idle":"2024-11-05T17:08:41.299063Z","shell.execute_reply.started":"2024-11-05T17:08:41.293481Z","shell.execute_reply":"2024-11-05T17:08:41.298327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# code inspired from https://www.pluralsight.com/guides/introduction-to-resnet\n    \n    # Huấn luyện mô hình qua nhiều epochs\nfor epoch in range(1, n_epochs + 1):\n    running_loss = 0.0  # Tổng mất mát trong một epoch\n    correct = 0  # Số lượng dự đoán đúng\n    total = 0  # Tổng số mẫu trong epoch\n    print(f'Epoch {epoch}\\n')\n\n    # Huấn luyện qua các mini-batches trong tập huấn luyện\n    for batch_idx, (data_, target_) in enumerate(training_dataloader):\n        data_, target_ = data_.to(device), target_.to(device)  # Di chuyển dữ liệu vào thiết bị (CPU hoặc GPU)\n        optimizer.zero_grad()  # Xoá gradient trước khi tính toán gradient mới\n\n        outputs = fine_tuned_vgg_model(data_)  # Dự đoán đầu ra từ mô hình\n        loss = criterion(outputs, target_)  # Tính toán mất mát\n        loss.backward()  # Lan truyền gradient ngược\n        optimizer.step()  # Cập nhật trọng số của mô hình\n\n        running_loss += loss.item()  # Cộng dồn mất mát\n        _, pred = torch.max(outputs, dim=1)  # Tính toán dự đoán\n        correct += torch.sum(pred == target_).item()  # Tính số lượng dự đoán đúng\n        total += target_.size(0)  # Tổng số mẫu trong batch\n\n        # In kết quả sau mỗi vài bước huấn luyện\n        if (batch_idx) % print_every == 0:\n            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n                  .format(epoch, n_epochs, batch_idx, total_step, loss.item()))\n\n    # Tính toán và lưu trữ độ chính xác và mất mát trung bình trên tập huấn luyện\n    train_acc.append(100 * correct / total)\n    train_loss.append(running_loss / total_step)\n    print(f'\\ntrain-loss: {np.mean(train_loss):.4f}, train-acc: {(100 * correct / total):.4f}%')\n\n    batch_loss = 0  # Mất mát trên tập kiểm tra\n    total_t = 0  # Tổng số mẫu trong tập kiểm tra\n    correct_t = 0  # Số lượng dự đoán đúng trên tập kiểm tra\n\n    # Đánh giá mô hình trên tập kiểm tra (validation)\n    with torch.no_grad():  # Tắt gradient khi đánh giá\n        fine_tuned_vgg_model.eval()  # Đặt mô hình vào chế độ đánh giá\n        for data_t, target_t in (testing_dataloader):\n            data_t, target_t = data_t.to(device), target_t.to(device)  # Di chuyển dữ liệu vào thiết bị\n            outputs_t = fine_tuned_vgg_model(data_t)  # Dự đoán đầu ra từ mô hình\n            loss_t = criterion(outputs_t, target_t)  # Tính toán mất mát trên tập kiểm tra\n            batch_loss += loss_t.item()  # Cộng dồn mất mát trên tập kiểm tra\n            _, pred_t = torch.max(outputs_t, dim=1)  # Tính toán dự đoán trên tập kiểm tra\n            correct_t += torch.sum(pred_t == target_t).item()  # Tính số lượng dự đoán đúng trên tập kiểm tra\n            total_t += target_t.size(0)  # Tổng số mẫu trong tập kiểm tra\n\n        # Tính toán và lưu trữ độ chính xác và mất mát trên tập kiểm tra\n        val_acc.append(100 * correct_t / total_t)\n        val_loss.append(batch_loss / len(testing_dataloader))\n        network_learned = batch_loss < valid_loss_min  # Kiểm tra xem mô hình có cải thiện không\n\n        print(f'validation loss: {np.mean(val_loss):.4f}, validation acc: {(100 * correct_t / total_t):.4f}%\\n')\n\n        # Lưu mô hình nếu có sự cải thiện về mất mát\n        if network_learned:\n            valid_loss_min = batch_loss\n            torch.save(fine_tuned_vgg_model.state_dict(), 'vgg_cifar10.pt')  # Lưu trọng số mô hình\n            print('Saving Parameters')\n\n    fine_tuned_vgg_model.train()  # Quay lại chế độ huấn luyện sau khi đánh giá\n","metadata":{"id":"radical-matter","scrolled":true,"execution":{"iopub.status.busy":"2024-11-05T17:08:41.300081Z","iopub.execute_input":"2024-11-05T17:08:41.300317Z","iopub.status.idle":"2024-11-05T17:32:18.70447Z","shell.execute_reply.started":"2024-11-05T17:08:41.300293Z","shell.execute_reply":"2024-11-05T17:32:18.70334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(val_loss)","metadata":{"id":"contained-sending","execution":{"iopub.status.busy":"2024-11-05T17:32:18.708773Z","iopub.execute_input":"2024-11-05T17:32:18.709198Z","iopub.status.idle":"2024-11-05T17:32:18.83052Z","shell.execute_reply.started":"2024-11-05T17:32:18.709166Z","shell.execute_reply":"2024-11-05T17:32:18.82977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(val_acc)\nplt.title('Testing Set Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy %')","metadata":{"id":"attached-popularity","execution":{"iopub.status.busy":"2024-11-05T17:32:18.831649Z","iopub.execute_input":"2024-11-05T17:32:18.832069Z","iopub.status.idle":"2024-11-05T17:32:18.973586Z","shell.execute_reply.started":"2024-11-05T17:32:18.832035Z","shell.execute_reply":"2024-11-05T17:32:18.972736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models.vgg16","metadata":{"id":"spiritual-possibility","execution":{"iopub.status.busy":"2024-11-05T17:32:18.974789Z","iopub.execute_input":"2024-11-05T17:32:18.975079Z","iopub.status.idle":"2024-11-05T17:32:18.979897Z","shell.execute_reply.started":"2024-11-05T17:32:18.975051Z","shell.execute_reply":"2024-11-05T17:32:18.979131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cifar_fine_tuned_vgg_model = models.vgg11(pretrained='imagenet')  # A\ncifar_fine_tuned_vgg_model.classifier[-1].out_features = 10  # A\n\ncifar_fine_tuned_vgg_model.load_state_dict(torch.load('vgg_cifar10.pt', map_location=device))  # B\n\ncifar_finetuned_training_images, shuffled_training_labels, cifar_finetuned_testing_images, shuffled_testing_labels = get_vgg_features(cifar_fine_tuned_vgg_model.features)  # B\n\nprint(\"Fine-tuned VGG11 + LogReg\\n=====================\")\nadvanced_grid_search(  # C\n    cifar_finetuned_training_images, shuffled_training_labels,\n    cifar_finetuned_testing_images, shuffled_testing_labels,\n    ml_pipeline, params\n)\n\n# A Khởi tạo một mô hình VGG-11 mới\n# B Tải các tham số được đào tạo và trích xuất các đặc trưng được tinh chỉnh\n# C Chạy tìm kiếm lưới trên các đặc trưng được tinh chỉnh","metadata":{"id":"official-subsection","execution":{"iopub.status.busy":"2024-11-05T17:32:18.981087Z","iopub.execute_input":"2024-11-05T17:32:18.981407Z"},"trusted":true},"execution_count":null,"outputs":[]}]}